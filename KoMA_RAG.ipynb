{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWLI0snd36MZ"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# KOMA-RAG: Retrieval-Augmented Hierarchical Multi-Agent Framework\n",
        "# Complete Modular Implementation for Google Colab\n",
        "# =============================================================================\n",
        "\n",
        "\"\"\"\n",
        "██╗  ██╗ ██████╗ ███╗   ███╗ █████╗       ██████╗  █████╗  ██████╗\n",
        "██║ ██╔╝██╔═══██╗████╗ ████║██╔══██╗      ██╔══██╗██╔══██╗██╔════╝\n",
        "█████╔╝ ██║   ██║██╔████╔██║███████║█████╗██████╔╝███████║██║  ███╗\n",
        "██╔═██╗ ██║   ██║██║╚██╔╝██║██╔══██║╚════╝██╔══██╗██╔══██║██║   ██║\n",
        "██║  ██╗╚██████╔╝██║ ╚═╝ ██║██║  ██║      ██║  ██║██║  ██║╚██████╔╝\n",
        "╚═╝  ╚═╝ ╚═════╝ ╚═╝     ╚═╝╚═╝  ╚═╝      ╚═╝  ╚═╝╚═╝  ╚═╝ ╚═════╝\n",
        "\n",
        "Retrieval-Augmented Hierarchical Multi-Agent Guided Framework\n",
        "for Autonomous Driving Decision Making\n",
        "\"\"\"\n",
        "\n",
        "# =============================================================================\n",
        "# PHASE 0: INSTALLATION AND IMPORTS\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PHASE 0: Installing Dependencies and Setting Up Environment\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q faiss-cpu sentence-transformers groq openai numpy pandas matplotlib seaborn tqdm\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass, field, asdict\n",
        "from typing import List, Dict, Tuple, Optional, Any, Union\n",
        "from enum import Enum\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Vector store and embeddings\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# LLM APIs\n",
        "try:\n",
        "    from groq import Groq\n",
        "    GROQ_AVAILABLE = True\n",
        "except ImportError:\n",
        "    GROQ_AVAILABLE = False\n",
        "    print(\"Groq not available\")\n",
        "\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "    OPENAI_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPENAI_AVAILABLE = False\n",
        "    print(\"OpenAI not available\")\n",
        "\n",
        "print(\"✓ All dependencies loaded successfully!\")\n",
        "\n",
        "# =============================================================================\n",
        "# PHASE 1: CONFIGURATION AND API SETUP\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PHASE 1: Configuration and API Setup\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "class LLMProvider(Enum):\n",
        "    \"\"\"Supported LLM Providers\"\"\"\n",
        "    GROQ = \"groq\"\n",
        "    OPENAI = \"openai\"\n",
        "    MOCK = \"mock\"  # For testing without API\n",
        "\n",
        "@dataclass\n",
        "class APIConfig:\n",
        "    \"\"\"API Configuration for LLM providers\"\"\"\n",
        "    provider: LLMProvider = LLMProvider.GROQ\n",
        "    groq_api_key: str = \"\"\n",
        "    openai_api_key: str = \"\"\n",
        "    groq_model: str = \"llama-3.1-8b-instant\"  # Free tier model\n",
        "    openai_model: str = \"gpt-3.5-turbo\"\n",
        "    temperature: float = 0.7\n",
        "    max_tokens: int = 1024\n",
        "\n",
        "@dataclass\n",
        "class FrameworkConfig:\n",
        "    \"\"\"Main framework configuration for ablation studies\"\"\"\n",
        "    # Ablation toggles\n",
        "    enable_master_agent: bool = True\n",
        "    enable_rag_verification: bool = True\n",
        "    enable_reflection: bool = True\n",
        "    enable_intent_inference: bool = True\n",
        "\n",
        "    # RAG parameters\n",
        "    k_candidates: int = 5  # k' - candidates to retrieve\n",
        "    k_final: int = 3  # k - final memories to use\n",
        "    tau_verify: float = 0.5  # Verification threshold\n",
        "    lambda_time: float = 0.1  # Temporal decay\n",
        "\n",
        "    # Master Agent parameters\n",
        "    lambda_coop: float = 0.3\n",
        "    lambda_conflict: float = 0.5\n",
        "    delta_t_safe: float = 2.0  # Safe time gap in seconds\n",
        "\n",
        "    # Reward parameters\n",
        "    gamma: float = 0.99\n",
        "    theta_reflect: float = -0.5  # Reflection trigger threshold\n",
        "    theta_high: float = 0.7  # High reward threshold\n",
        "\n",
        "    # Environment parameters\n",
        "    num_agents: int = 2\n",
        "    num_idm_vehicles: int = 2\n",
        "    num_lanes: int = 4\n",
        "    road_length: float = 500.0\n",
        "    max_timesteps: int = 50\n",
        "\n",
        "    # Embedding dimension\n",
        "    embedding_dim: int = 384\n",
        "\n",
        "@dataclass\n",
        "class ExperimentConfig:\n",
        "    \"\"\"Experiment configuration\"\"\"\n",
        "    experiment_name: str = \"koma_rag_experiment\"\n",
        "    num_episodes: int = 2\n",
        "    seed: int = 42\n",
        "    verbose: bool = True\n",
        "    save_results: bool = True\n",
        "\n",
        "# =============================================================================\n",
        "# API KEY SETUP - MODIFY THIS SECTION\n",
        "# =============================================================================\n",
        "def setup_api_keys():\n",
        "    \"\"\"\n",
        "    Setup API keys for LLM providers.\n",
        "\n",
        "    INSTRUCTIONS:\n",
        "    1. For GROQ (FREE): Get key from https://console.groq.com/keys\n",
        "    2. For OpenAI: Get key from https://platform.openai.com/api-keys\n",
        "\n",
        "    Set your preferred provider and API key below:\n",
        "    \"\"\"\n",
        "\n",
        "    # ========== MODIFY THESE VALUES ==========\n",
        "    PREFERRED_PROVIDER = LLMProvider.GROQ  # Change to LLMProvider.OPENAI if needed\n",
        "\n",
        "    # Option 1: Direct assignment (not recommended for sharing)\n",
        "    GROQ_API_KEY = \"\"  # Your Groq API key here\n",
        "    OPENAI_API_KEY = \"\"  # Your OpenAI API key here\n",
        "\n",
        "    # Option 2: From environment variables \n",
        "    if not GROQ_API_KEY:\n",
        "        GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\", \"\")\n",
        "    if not OPENAI_API_KEY:\n",
        "        OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
        "\n",
        "    # Option 3: From Colab secrets\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        if not GROQ_API_KEY:\n",
        "            GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "        if not OPENAI_API_KEY:\n",
        "            OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    except:\n",
        "        pass\n",
        "    # ==========================================\n",
        "\n",
        "    # Validate and create config\n",
        "    api_config = APIConfig(\n",
        "        provider=PREFERRED_PROVIDER,\n",
        "        groq_api_key=GROQ_API_KEY,\n",
        "        openai_api_key=OPENAI_API_KEY\n",
        "    )\n",
        "\n",
        "    # Fallback to mock if no keys available\n",
        "    if api_config.provider == LLMProvider.GROQ and not api_config.groq_api_key:\n",
        "        print(\"⚠ No Groq API key found. Falling back to mock LLM.\")\n",
        "        api_config.provider = LLMProvider.MOCK\n",
        "    elif api_config.provider == LLMProvider.OPENAI and not api_config.openai_api_key:\n",
        "        print(\"⚠ No OpenAI API key found. Falling back to mock LLM.\")\n",
        "        api_config.provider = LLMProvider.MOCK\n",
        "\n",
        "    print(f\"✓ Using LLM Provider: {api_config.provider.value}\")\n",
        "    return api_config\n",
        "\n",
        "# Initialize configurations\n",
        "api_config = setup_api_keys()\n",
        "framework_config = FrameworkConfig()\n",
        "experiment_config = ExperimentConfig()\n",
        "\n",
        "print(f\"✓ Framework configured with:\")\n",
        "print(f\"  - Master Agent: {'Enabled' if framework_config.enable_master_agent else 'Disabled'}\")\n",
        "print(f\"  - RAG Verification: {'Enabled' if framework_config.enable_rag_verification else 'Disabled'}\")\n",
        "print(f\"  - Reflection Module: {'Enabled' if framework_config.enable_reflection else 'Disabled'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvz6_8p44Atu"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PHASE 2: CORE DATA STRUCTURES\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PHASE 2: Defining Core Data Structures\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "class Action(Enum):\n",
        "    \"\"\"Action space A_i as defined in the formulation\"\"\"\n",
        "    IDLE = 0\n",
        "    ACCELERATE = 1\n",
        "    DECELERATE = 2\n",
        "    LANE_CHANGE_LEFT = 3\n",
        "    LANE_CHANGE_RIGHT = 4\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.name\n",
        "\n",
        "@dataclass\n",
        "class AgentState:\n",
        "    \"\"\"\n",
        "    Agent state s_i(t) = [x_i, y_i, θ_i, v_i, a_i, l_i, g_i, π_i]^T\n",
        "    Extended with goal and priority for KoMA-RAG\n",
        "    \"\"\"\n",
        "    agent_id: str\n",
        "    x: float  # Position x\n",
        "    y: float  # Position y (lane position)\n",
        "    theta: float  # Heading angle\n",
        "    velocity: float  # Current velocity\n",
        "    acceleration: float  # Current acceleration\n",
        "    lane: int  # Current lane\n",
        "    goal: Optional[str] = None  # g_i(t) - assigned goal\n",
        "    priority: float = 0.5  # π_i(t) - priority level [0,1]\n",
        "    is_ego: bool = True  # True for LLM agents, False for IDM vehicles\n",
        "\n",
        "    def to_vector(self) -> np.ndarray:\n",
        "        \"\"\"Convert to numerical vector\"\"\"\n",
        "        return np.array([self.x, self.y, self.theta, self.velocity,\n",
        "                        self.acceleration, self.lane, self.priority])\n",
        "\n",
        "    def to_description(self) -> str:\n",
        "        \"\"\"Generate natural language description\"\"\"\n",
        "        return (f\"Agent {self.agent_id}: Position ({self.x:.1f}, {self.y:.1f}), \"\n",
        "                f\"Lane {self.lane}, Velocity {self.velocity:.1f} m/s, \"\n",
        "                f\"Acceleration {self.acceleration:.1f} m/s², \"\n",
        "                f\"Heading {self.theta:.1f}°, Priority {self.priority:.2f}\")\n",
        "\n",
        "@dataclass\n",
        "class Experience:\n",
        "    \"\"\"\n",
        "    Memory experience e_k = (D_k, G_k, P_k, u_k, r_k, z_k)\n",
        "    \"\"\"\n",
        "    experience_id: str\n",
        "    description: str  # D_k - scenario description\n",
        "    goal: str  # G_k - goal\n",
        "    plan: str  # P_k - plan\n",
        "    action: Action  # u_k - action taken\n",
        "    reward: float  # r_k - reward received\n",
        "    embedding: Optional[np.ndarray] = None  # z_k - embedding vector\n",
        "    timestamp: float = 0.0  # t_k - time of experience\n",
        "    scenario_type: str = \"highway\"  # Type of scenario\n",
        "    verified: bool = False  # Verification status\n",
        "\n",
        "    def to_dict(self) -> Dict:\n",
        "        return {\n",
        "            'experience_id': self.experience_id,\n",
        "            'description': self.description,\n",
        "            'goal': self.goal,\n",
        "            'plan': self.plan,\n",
        "            'action': self.action.name,\n",
        "            'reward': self.reward,\n",
        "            'timestamp': self.timestamp,\n",
        "            'scenario_type': self.scenario_type,\n",
        "            'verified': self.verified\n",
        "        }\n",
        "\n",
        "@dataclass\n",
        "class CoordinationMessage:\n",
        "    \"\"\"\n",
        "    Master-to-Agent message: msg_{M→i}(t)\n",
        "    \"\"\"\n",
        "    target_agent_id: str\n",
        "    assigned_goal: str\n",
        "    assigned_priority: float\n",
        "    coordination_constraints: List[str]\n",
        "    timestamp: float\n",
        "\n",
        "@dataclass\n",
        "class AgentReport:\n",
        "    \"\"\"\n",
        "    Agent-to-Master message: msg_{i→M}(t)\n",
        "    \"\"\"\n",
        "    agent_id: str\n",
        "    state: AgentState\n",
        "    proposed_goal: str\n",
        "    inferred_intentions: Dict[str, str]\n",
        "    confidence: float\n",
        "    timestamp: float\n",
        "\n",
        "@dataclass\n",
        "class ScenarioDescription:\n",
        "    \"\"\"Complete scenario description D(t)\"\"\"\n",
        "    timestamp: float\n",
        "    driving_task: str\n",
        "    ego_states: Dict[str, AgentState]\n",
        "    traffic_info: List[AgentState]\n",
        "    road_conditions: Dict[str, Any]\n",
        "    coordination_state: Optional[Dict] = None\n",
        "\n",
        "    def to_text(self) -> str:\n",
        "        \"\"\"Generate comprehensive text description\"\"\"\n",
        "        text_parts = [\n",
        "            f\"=== SCENARIO AT t={self.timestamp:.2f}s ===\",\n",
        "            f\"\\nDRIVING TASK: {self.driving_task}\",\n",
        "            f\"\\nROAD CONDITIONS:\",\n",
        "            f\"  - Number of lanes: {self.road_conditions.get('num_lanes', 4)}\",\n",
        "            f\"  - Road length: {self.road_conditions.get('road_length', 500)}m\",\n",
        "            f\"  - Speed limit: {self.road_conditions.get('speed_limit', 30)} m/s\",\n",
        "            f\"\\nEGO VEHICLES ({len(self.ego_states)} agents):\"\n",
        "        ]\n",
        "\n",
        "        for agent_id, state in self.ego_states.items():\n",
        "            text_parts.append(f\"  {state.to_description()}\")\n",
        "\n",
        "        text_parts.append(f\"\\nSURROUNDING TRAFFIC ({len(self.traffic_info)} vehicles):\")\n",
        "        for vehicle in self.traffic_info:\n",
        "            text_parts.append(f\"  {vehicle.to_description()}\")\n",
        "\n",
        "        if self.coordination_state:\n",
        "            text_parts.append(f\"\\nCOORDINATION STATE:\")\n",
        "            for key, value in self.coordination_state.items():\n",
        "                text_parts.append(f\"  - {key}: {value}\")\n",
        "\n",
        "        return \"\\n\".join(text_parts)\n",
        "\n",
        "print(\"✓ Core data structures defined:\")\n",
        "print(f\"  - Action space: {[a.name for a in Action]}\")\n",
        "print(f\"  - AgentState with {len(AgentState.__dataclass_fields__)} fields\")\n",
        "print(f\"  - Experience structure for memory storage\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jwh2DiJw4GkK"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PHASE 3: LLM INTERFACE MODULE \n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PHASE 3: LLM Interface Module\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "class LLMInterface:\n",
        "    \"\"\"Unified interface for LLM providers with robust JSON handling\"\"\"\n",
        "\n",
        "    def __init__(self, config: APIConfig):\n",
        "        self.config = config\n",
        "        self.client = None\n",
        "        self.call_count = 0\n",
        "        self.error_count = 0\n",
        "        self._initialize_client()\n",
        "\n",
        "    def _initialize_client(self):\n",
        "        if self.config.provider == LLMProvider.GROQ:\n",
        "            self.client = Groq(api_key=self.config.groq_api_key)\n",
        "            print(f\"✓ Groq client initialized: {self.config.groq_model}\")\n",
        "        elif self.config.provider == LLMProvider.OPENAI:\n",
        "            self.client = OpenAI(api_key=self.config.openai_api_key)\n",
        "            print(f\"✓ OpenAI client initialized: {self.config.openai_model}\")\n",
        "        else:\n",
        "            print(\"✓ Mock LLM initialized\")\n",
        "\n",
        "    def _extract_json(self, text: str) -> Optional[Dict]:\n",
        "        \"\"\"Extract and parse JSON from text\"\"\"\n",
        "        # Remove markdown\n",
        "        text = re.sub(r'```json\\s*', '', text)\n",
        "        text = re.sub(r'```\\s*', '', text)\n",
        "\n",
        "        # Find JSON object\n",
        "        match = re.search(r'\\{[^{}]*\\}', text, re.DOTALL)\n",
        "        if match:\n",
        "            try:\n",
        "                return json.loads(match.group())\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Try full text\n",
        "        try:\n",
        "            return json.loads(text.strip())\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def generate(self, prompt: str, system_prompt: str = None,\n",
        "                 json_mode: bool = False) -> str:\n",
        "        \"\"\"Generate response from LLM\"\"\"\n",
        "        self.call_count += 1\n",
        "\n",
        "        if self.config.provider == LLMProvider.MOCK:\n",
        "            return self._mock_generate(prompt)\n",
        "\n",
        "        messages = []\n",
        "        if system_prompt:\n",
        "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
        "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "        try:\n",
        "            if self.config.provider == LLMProvider.GROQ:\n",
        "                response = self.client.chat.completions.create(\n",
        "                    model=self.config.groq_model,\n",
        "                    messages=messages,\n",
        "                    temperature=self.config.temperature,\n",
        "                    max_tokens=self.config.max_tokens\n",
        "                )\n",
        "                result = response.choices[0].message.content\n",
        "\n",
        "                if json_mode:\n",
        "                    parsed = self._extract_json(result)\n",
        "                    if parsed:\n",
        "                        return json.dumps(parsed)\n",
        "                    return self._mock_generate(prompt)\n",
        "                return result\n",
        "\n",
        "            elif self.config.provider == LLMProvider.OPENAI:\n",
        "                response = self.client.chat.completions.create(\n",
        "                    model=self.config.openai_model,\n",
        "                    messages=messages,\n",
        "                    temperature=self.config.temperature,\n",
        "                    max_tokens=self.config.max_tokens\n",
        "                )\n",
        "                return response.choices[0].message.content\n",
        "\n",
        "        except Exception as e:\n",
        "            self.error_count += 1\n",
        "            print(f\"⚠ LLM Error: {str(e)[:80]}\")\n",
        "            return self._mock_generate(prompt)\n",
        "\n",
        "    def _mock_generate(self, prompt: str) -> str:\n",
        "        \"\"\"Generate mock responses\"\"\"\n",
        "        prompt_lower = prompt.lower()\n",
        "\n",
        "        if \"goal\" in prompt_lower:\n",
        "            return json.dumps({\n",
        "                \"goal\": \"Maintain safe lane position\",\n",
        "                \"reasoning\": \"Current traffic is manageable\"\n",
        "            })\n",
        "        elif \"plan\" in prompt_lower:\n",
        "            return json.dumps({\n",
        "                \"plan\": [\"Monitor traffic\", \"Maintain distance\", \"Adjust speed\"],\n",
        "                \"expected_outcome\": \"Safe navigation\"\n",
        "            })\n",
        "        elif \"action\" in prompt_lower:\n",
        "            return json.dumps({\n",
        "                \"action\": random.choice([\"IDLE\", \"ACCELERATE\", \"DECELERATE\"]),\n",
        "                \"confidence\": round(random.uniform(0.7, 0.95), 2)\n",
        "            })\n",
        "        elif \"consistent\" in prompt_lower or \"verify\" in prompt_lower:\n",
        "            return json.dumps({\n",
        "                \"is_consistent\": random.random() > 0.3,\n",
        "                \"confidence\": round(random.uniform(0.6, 0.9), 2),\n",
        "                \"reason\": \"Context comparison completed\"\n",
        "            })\n",
        "        elif \"reflect\" in prompt_lower:\n",
        "            return json.dumps({\n",
        "                \"analysis\": \"Action was appropriate\",\n",
        "                \"corrected_goal\": \"Maintain position\",\n",
        "                \"corrected_plan\": \"Continue monitoring\",\n",
        "                \"corrected_action\": \"IDLE\"\n",
        "            })\n",
        "        else:\n",
        "            return json.dumps({\"status\": \"ok\"})\n",
        "\n",
        "    def get_stats(self) -> Dict:\n",
        "        return {\n",
        "            \"provider\": self.config.provider.value,\n",
        "            \"calls\": self.call_count,\n",
        "            \"errors\": self.error_count\n",
        "        }\n",
        "\n",
        "# Initialize LLM\n",
        "llm = LLMInterface(api_config)\n",
        "print(f\"✓ LLM ready: {llm.get_stats()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95T-Ar8W4Kpi"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PHASE 4: EMBEDDING AND FAISS VECTOR STORE\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PHASE 4: Embedding and FAISS Vector Store\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "class EmbeddingModule:\n",
        "    \"\"\"Embedding module: z_i(t) = Embed(Ω_i(t))\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n",
        "        print(f\"Loading embedding model: {model_name}\")\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        self.embedding_dim = self.model.get_sentence_embedding_dimension()\n",
        "        print(f\"✓ Model loaded. Dimension: {self.embedding_dim}\")\n",
        "\n",
        "    def embed(self, text: str) -> np.ndarray:\n",
        "        return self.model.encode(text, convert_to_numpy=True)\n",
        "\n",
        "    def embed_batch(self, texts: List[str]) -> np.ndarray:\n",
        "        return self.model.encode(texts, convert_to_numpy=True)\n",
        "\n",
        "    def cosine_similarity(self, v1: np.ndarray, v2: np.ndarray) -> float:\n",
        "        norm1, norm2 = np.linalg.norm(v1), np.linalg.norm(v2)\n",
        "        if norm1 == 0 or norm2 == 0:\n",
        "            return 0.0\n",
        "        return float(np.dot(v1, v2) / (norm1 * norm2))\n",
        "\n",
        "\n",
        "class FAISSVectorStore:\n",
        "    \"\"\"FAISS vector store for memory retrieval\"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim: int):\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.index = faiss.IndexFlatIP(embedding_dim)\n",
        "        self.experiences: List[Experience] = []\n",
        "        print(f\"✓ FAISS index initialized (dim={embedding_dim})\")\n",
        "\n",
        "    def add_experience(self, experience: Experience):\n",
        "        if experience.embedding is None:\n",
        "            raise ValueError(\"Experience must have embedding\")\n",
        "\n",
        "        embedding = experience.embedding / np.linalg.norm(experience.embedding)\n",
        "        embedding = embedding.reshape(1, -1).astype('float32')\n",
        "\n",
        "        self.index.add(embedding)\n",
        "        self.experiences.append(experience)\n",
        "\n",
        "    def search(self, query_embedding: np.ndarray, k: int) -> List[Tuple[Experience, float]]:\n",
        "        if len(self.experiences) == 0:\n",
        "            return []\n",
        "\n",
        "        query = query_embedding / np.linalg.norm(query_embedding)\n",
        "        query = query.reshape(1, -1).astype('float32')\n",
        "\n",
        "        k = min(k, len(self.experiences))\n",
        "        scores, indices = self.index.search(query, k)\n",
        "\n",
        "        results = []\n",
        "        for score, idx in zip(scores[0], indices[0]):\n",
        "            if idx >= 0:\n",
        "                results.append((self.experiences[idx], float(score)))\n",
        "        return results\n",
        "\n",
        "    def get_all_experiences(self) -> List[Experience]:\n",
        "        return self.experiences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.experiences)\n",
        "\n",
        "# Initialize\n",
        "embedding_module = EmbeddingModule()\n",
        "vector_store = FAISSVectorStore(embedding_module.embedding_dim)\n",
        "print(f\"✓ Vector store ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D47_Q54G4PAx"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PHASE 5: RAG-ENHANCED MEMORY MODULE \n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PHASE 5: RAG-Enhanced Memory Module\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "class VerificationModule:\n",
        "    \"\"\"Composite Verification: V(e_j, Ω_i(t)) = V_semantic × V_factual × V_contextual\"\"\"\n",
        "\n",
        "    def __init__(self, llm: LLMInterface, embedding_module: EmbeddingModule,\n",
        "                 config: FrameworkConfig):\n",
        "        self.llm = llm\n",
        "        self.embedding_module = embedding_module\n",
        "        self.config = config\n",
        "\n",
        "    def compute_semantic_score(self, experience: Experience,\n",
        "                                query_embedding: np.ndarray) -> float:\n",
        "        if experience.embedding is None:\n",
        "            return 0.0\n",
        "        return self.embedding_module.cosine_similarity(\n",
        "            experience.embedding, query_embedding\n",
        "        )\n",
        "\n",
        "    def compute_factual_score(self, experience: Experience, context: str) -> float:\n",
        "        \"\"\"V_factual with simplified prompt\"\"\"\n",
        "        if not self.config.enable_rag_verification:\n",
        "            return 1.0\n",
        "\n",
        "        exp_short = experience.description[:200]\n",
        "        ctx_short = context[:300]\n",
        "\n",
        "        prompt = f\"\"\"Is this past experience applicable to current situation?\n",
        "\n",
        "Past: {exp_short}\n",
        "Action: {experience.action.name}, Reward: {experience.reward:.1f}\n",
        "\n",
        "Current: {ctx_short}\n",
        "\n",
        "Reply with JSON only:\n",
        "{{\"is_consistent\": true, \"confidence\": 0.8, \"reason\": \"brief reason\"}}\"\"\"\n",
        "\n",
        "        system = \"Reply with valid JSON only. No other text.\"\n",
        "\n",
        "        try:\n",
        "            response = self.llm.generate(prompt, system, json_mode=True)\n",
        "            result = json.loads(response)\n",
        "            if result.get(\"is_consistent\", False):\n",
        "                return float(result.get(\"confidence\", 0.7))\n",
        "            return 0.2\n",
        "        except:\n",
        "            return 0.5\n",
        "\n",
        "    def compute_contextual_score(self, experience: Experience,\n",
        "                                  current_time: float,\n",
        "                                  scenario_type: str) -> float:\n",
        "        time_diff = abs(experience.timestamp - current_time)\n",
        "        temporal = np.exp(-self.config.lambda_time * time_diff)\n",
        "        scenario_match = 1.0 if experience.scenario_type == scenario_type else 0.3\n",
        "        return temporal * scenario_match\n",
        "\n",
        "    def verify(self, experience: Experience, context: str,\n",
        "               query_embedding: np.ndarray, current_time: float,\n",
        "               scenario_type: str = \"highway\") -> float:\n",
        "        v_sem = self.compute_semantic_score(experience, query_embedding)\n",
        "        v_fact = self.compute_factual_score(experience, context)\n",
        "        v_ctx = self.compute_contextual_score(experience, current_time, scenario_type)\n",
        "\n",
        "        # Weighted average instead of product\n",
        "        return 0.5 * v_sem + 0.3 * v_fact + 0.2 * v_ctx\n",
        "\n",
        "\n",
        "class RAGMemoryModule:\n",
        "    \"\"\"RAG-Enhanced Shared Memory with two-stage retrieval\"\"\"\n",
        "\n",
        "    def __init__(self, vector_store: FAISSVectorStore,\n",
        "                 embedding_module: EmbeddingModule,\n",
        "                 verification_module: VerificationModule,\n",
        "                 config: FrameworkConfig):\n",
        "        self.vector_store = vector_store\n",
        "        self.embedding_module = embedding_module\n",
        "        self.verification = verification_module\n",
        "        self.config = config\n",
        "        self.stats = defaultdict(int)\n",
        "\n",
        "    def add_experience(self, experience: Experience):\n",
        "        if experience.embedding is None:\n",
        "            text = f\"{experience.description} {experience.goal} {experience.plan}\"\n",
        "            experience.embedding = self.embedding_module.embed(text)\n",
        "        self.vector_store.add_experience(experience)\n",
        "        self.stats['added'] += 1\n",
        "\n",
        "    def retrieve(self, context: str, current_time: float,\n",
        "                 scenario_type: str = \"highway\") -> List[Experience]:\n",
        "        \"\"\"Two-stage retrieval with verification\"\"\"\n",
        "        query_emb = self.embedding_module.embed(context)\n",
        "\n",
        "        # Stage 1: Candidates\n",
        "        candidates = self.vector_store.search(query_emb, self.config.k_candidates)\n",
        "        self.stats['candidates'] += len(candidates)\n",
        "\n",
        "        if not candidates:\n",
        "            return []\n",
        "\n",
        "        # Stage 2: Verification\n",
        "        verified = []\n",
        "        for exp, sim in candidates:\n",
        "            if self.config.enable_rag_verification:\n",
        "                score = self.verification.verify(exp, context, query_emb, current_time, scenario_type)\n",
        "            else:\n",
        "                score = sim\n",
        "\n",
        "            if score > self.config.tau_verify:\n",
        "                verified.append((exp, score))\n",
        "                self.stats['verified'] += 1\n",
        "            else:\n",
        "                self.stats['rejected'] += 1\n",
        "\n",
        "        verified.sort(key=lambda x: x[1], reverse=True)\n",
        "        return [exp for exp, _ in verified[:self.config.k_final]]\n",
        "\n",
        "    def get_stats(self) -> Dict:\n",
        "        s = dict(self.stats)\n",
        "        s['total'] = len(self.vector_store)\n",
        "        return s\n",
        "\n",
        "# Initialize\n",
        "verification_module = VerificationModule(llm, embedding_module, framework_config)\n",
        "memory_module = RAGMemoryModule(vector_store, embedding_module, verification_module, framework_config)\n",
        "print(f\"✓ RAG Memory initialized (verification: {framework_config.enable_rag_verification})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3btDhiyP4Uno"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PHASE 6: ENVIRONMENT SIMULATION\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PHASE 6: Environment Simulation\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "class IDMVehicle:\n",
        "    \"\"\"Intelligent Driver Model vehicle\"\"\"\n",
        "    V0, T, A, B, S0, DELTA = 30.0, 1.5, 1.5, 2.0, 2.0, 4\n",
        "\n",
        "    def __init__(self, vehicle_id: str, state: AgentState):\n",
        "        self.vehicle_id = vehicle_id\n",
        "        self.state = state\n",
        "        self.state.is_ego = False\n",
        "\n",
        "    def compute_acceleration(self, leader: Optional[AgentState] = None) -> float:\n",
        "        v = self.state.velocity\n",
        "        a_free = self.A * (1 - (v / self.V0) ** self.DELTA)\n",
        "\n",
        "        if leader is None:\n",
        "            return a_free\n",
        "\n",
        "        s = leader.x - self.state.x - 5.0\n",
        "        if s <= 0:\n",
        "            return -self.B\n",
        "\n",
        "        delta_v = v - leader.velocity\n",
        "        s_star = self.S0 + max(0, v * self.T + (v * delta_v) / (2 * np.sqrt(self.A * self.B)))\n",
        "        return a_free - self.A * (s_star / s) ** 2\n",
        "\n",
        "    def update(self, dt: float, leader: Optional[AgentState] = None):\n",
        "        acc = np.clip(self.compute_acceleration(leader), -self.B, self.A)\n",
        "        self.state.acceleration = acc\n",
        "        self.state.velocity = max(0, self.state.velocity + acc * dt)\n",
        "        self.state.x += self.state.velocity * dt\n",
        "\n",
        "\n",
        "class HighwayEnvironment:\n",
        "    \"\"\"Highway simulation environment\"\"\"\n",
        "\n",
        "    def __init__(self, config: FrameworkConfig):\n",
        "        self.config = config\n",
        "        self.ego_agents: Dict[str, AgentState] = {}\n",
        "        self.idm_vehicles: Dict[str, IDMVehicle] = {}\n",
        "        self.timestep = 0\n",
        "        self.current_time = 0.0\n",
        "        self.dt = 0.1\n",
        "        self.collision_occurred = False\n",
        "        self.episode_rewards: List[float] = []\n",
        "        self._init_env()\n",
        "\n",
        "    def _init_env(self):\n",
        "        # Ego agents\n",
        "        for i in range(self.config.num_agents):\n",
        "            aid = f\"ego_{i}\"\n",
        "            self.ego_agents[aid] = AgentState(\n",
        "                agent_id=aid, x=50.0 + i * 30, y=float(i % self.config.num_lanes),\n",
        "                theta=0.0, velocity=20.0 + random.uniform(-5, 5),\n",
        "                acceleration=0.0, lane=i % self.config.num_lanes,\n",
        "                priority=0.5, is_ego=True\n",
        "            )\n",
        "\n",
        "        # IDM vehicles\n",
        "        for i in range(self.config.num_idm_vehicles):\n",
        "            vid = f\"idm_{i}\"\n",
        "            lane = random.randint(0, self.config.num_lanes - 1)\n",
        "            state = AgentState(\n",
        "                agent_id=vid, x=100.0 + i * 40 + random.uniform(-10, 10),\n",
        "                y=float(lane), theta=0.0, velocity=25.0 + random.uniform(-5, 5),\n",
        "                acceleration=0.0, lane=lane, priority=1.0, is_ego=False\n",
        "            )\n",
        "            self.idm_vehicles[vid] = IDMVehicle(vid, state)\n",
        "\n",
        "    def reset(self) -> ScenarioDescription:\n",
        "        self.timestep = 0\n",
        "        self.current_time = 0.0\n",
        "        self.collision_occurred = False\n",
        "        self.episode_rewards = []\n",
        "        self.ego_agents.clear()\n",
        "        self.idm_vehicles.clear()\n",
        "        self._init_env()\n",
        "        return self.get_scenario_description()\n",
        "\n",
        "    def get_scenario_description(self) -> ScenarioDescription:\n",
        "        return ScenarioDescription(\n",
        "            timestamp=self.current_time,\n",
        "            driving_task=\"Navigate highway safely\",\n",
        "            ego_states=self.ego_agents.copy(),\n",
        "            traffic_info=[v.state for v in self.idm_vehicles.values()],\n",
        "            road_conditions={'num_lanes': self.config.num_lanes,\n",
        "                           'road_length': self.config.road_length, 'speed_limit': 30.0}\n",
        "        )\n",
        "\n",
        "    def get_agent_context(self, agent_id: str) -> str:\n",
        "        state = self.ego_agents[agent_id]\n",
        "        nearby = [v.state for v in self.idm_vehicles.values()\n",
        "                  if abs(v.state.x - state.x) < 100]\n",
        "\n",
        "        ctx = f\"Agent {agent_id}: Pos {state.x:.1f}m, Lane {state.lane}, Vel {state.velocity:.1f} m/s\\n\"\n",
        "        ctx += f\"Nearby ({len(nearby)}): \"\n",
        "        for v in nearby[:3]:\n",
        "            ctx += f\"{v.agent_id}(lane {v.lane}, {v.x:.0f}m) \"\n",
        "        return ctx\n",
        "\n",
        "    def execute_action(self, agent_id: str, action: Action) -> Tuple[float, bool]:\n",
        "        state = self.ego_agents[agent_id]\n",
        "\n",
        "        if action == Action.ACCELERATE:\n",
        "            state.acceleration = 2.0\n",
        "        elif action == Action.DECELERATE:\n",
        "            state.acceleration = -2.0\n",
        "        elif action == Action.LANE_CHANGE_LEFT and state.lane < self.config.num_lanes - 1:\n",
        "            state.lane += 1\n",
        "            state.y = float(state.lane)\n",
        "        elif action == Action.LANE_CHANGE_RIGHT and state.lane > 0:\n",
        "            state.lane -= 1\n",
        "            state.y = float(state.lane)\n",
        "        else:\n",
        "            state.acceleration = 0.0\n",
        "\n",
        "        state.velocity = max(0, min(35, state.velocity + state.acceleration * self.dt))\n",
        "        state.x += state.velocity * self.dt\n",
        "\n",
        "        reward = self._calc_reward(agent_id, action)\n",
        "        collision = self._check_collision(agent_id)\n",
        "\n",
        "        if collision:\n",
        "            self.collision_occurred = True\n",
        "            reward -= 10.0\n",
        "\n",
        "        self.episode_rewards.append(reward)\n",
        "        return reward, collision\n",
        "\n",
        "    def _calc_reward(self, agent_id: str, action: Action) -> float:\n",
        "        state = self.ego_agents[agent_id]\n",
        "        reward = max(0, 1.0 - abs(state.velocity - 25.0) / 25.0)\n",
        "        reward += 0.1 * (state.velocity / 30.0)\n",
        "        if action in [Action.LANE_CHANGE_LEFT, Action.LANE_CHANGE_RIGHT]:\n",
        "            reward -= 0.2\n",
        "        return reward\n",
        "\n",
        "    def _check_collision(self, agent_id: str) -> bool:\n",
        "        state = self.ego_agents[agent_id]\n",
        "        for v in self.idm_vehicles.values():\n",
        "            dist = np.sqrt((v.state.x - state.x)**2 + (3.7 * (v.state.lane - state.lane))**2)\n",
        "            if dist < 5.0:\n",
        "                return True\n",
        "        for oid, ostate in self.ego_agents.items():\n",
        "            if oid != agent_id:\n",
        "                dist = np.sqrt((ostate.x - state.x)**2 + (3.7 * (ostate.lane - state.lane))**2)\n",
        "                if dist < 5.0:\n",
        "                    return True\n",
        "        return False\n",
        "\n",
        "    def step(self):\n",
        "        for v in self.idm_vehicles.values():\n",
        "            leader = None\n",
        "            min_d = float('inf')\n",
        "            for ov in self.idm_vehicles.values():\n",
        "                if ov.vehicle_id != v.vehicle_id and ov.state.lane == v.state.lane:\n",
        "                    d = ov.state.x - v.state.x\n",
        "                    if 0 < d < min_d:\n",
        "                        min_d, leader = d, ov.state\n",
        "            v.update(self.dt, leader)\n",
        "        self.timestep += 1\n",
        "        self.current_time += self.dt\n",
        "\n",
        "    def is_done(self) -> bool:\n",
        "        return self.timestep >= self.config.max_timesteps or self.collision_occurred\n",
        "\n",
        "# Initialize\n",
        "env = HighwayEnvironment(framework_config)\n",
        "print(f\"✓ Environment ready: {len(env.ego_agents)} agents, {len(env.idm_vehicles)} IDM vehicles\")\n",
        "print(\"\\n\" + env.get_scenario_description().to_text())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmwH4_n44Yyi"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PHASE 7: INTENT INFERENCE MODULE\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PHASE 7: Intent Inference Module\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "class IntentInferenceModule:\n",
        "    \"\"\"Infer intentions of nearby vehicles\"\"\"\n",
        "\n",
        "    def __init__(self, llm: LLMInterface, config: FrameworkConfig):\n",
        "        self.llm = llm\n",
        "        self.config = config\n",
        "\n",
        "    def infer_intentions(self, observer: AgentState, nearby: List[AgentState],\n",
        "                         current_time: float) -> Dict[str, str]:\n",
        "        if not self.config.enable_intent_inference:\n",
        "            return {}\n",
        "\n",
        "        intentions = {}\n",
        "        for v in nearby[:5]:\n",
        "            intentions[v.agent_id] = self._infer_single(observer, v)\n",
        "        return intentions\n",
        "\n",
        "    def _infer_single(self, observer: AgentState, target: AgentState) -> str:\n",
        "        if target.acceleration > 1.5:\n",
        "            return \"accelerating\"\n",
        "        elif target.acceleration < -1.5:\n",
        "            return \"braking\"\n",
        "        elif target.x > observer.x:\n",
        "            return \"ahead_maintaining\"\n",
        "        else:\n",
        "            return \"behind_following\"\n",
        "\n",
        "    def get_summary(self, observer_id: str, observer: AgentState,\n",
        "                    nearby: List[AgentState], intentions: Dict[str, str]) -> str:\n",
        "        s = f\"Context for {observer_id}:\\n\"\n",
        "        for v in nearby[:3]:\n",
        "            intent = intentions.get(v.agent_id, \"unknown\")\n",
        "            rel = \"ahead\" if v.x > observer.x else \"behind\"\n",
        "            s += f\"  {v.agent_id}: {rel}, lane {v.lane}, intent={intent}\\n\"\n",
        "        return s\n",
        "\n",
        "intent_module = IntentInferenceModule(llm, framework_config)\n",
        "print(\"✓ Intent Inference ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6AJJa6S4ceZ"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PHASE 8: MASTER COORDINATION MODULE\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PHASE 8: Master Coordination Module\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "class MasterCoordinationModule:\n",
        "    \"\"\"Master Agent for hierarchical coordination\"\"\"\n",
        "\n",
        "    def __init__(self, llm: LLMInterface, config: FrameworkConfig):\n",
        "        self.llm = llm\n",
        "        self.config = config\n",
        "        self.conflict_count = 0\n",
        "        self.resolution_count = 0\n",
        "\n",
        "    def detect_conflicts(self, goals: Dict[str, str],\n",
        "                         states: Dict[str, AgentState]) -> List[Tuple[str, str, str]]:\n",
        "        conflicts = []\n",
        "        aids = list(goals.keys())\n",
        "        for i, a1 in enumerate(aids):\n",
        "            for a2 in aids[i+1:]:\n",
        "                s1, s2 = states[a1], states[a2]\n",
        "                if s1.lane == s2.lane and abs(s1.x - s2.x) < 20:\n",
        "                    conflicts.append((a1, a2, \"proximity\"))\n",
        "                    self.conflict_count += 1\n",
        "        return conflicts\n",
        "\n",
        "    def compute_priorities(self, states: Dict[str, AgentState],\n",
        "                           goals: Dict[str, str]) -> Dict[str, float]:\n",
        "        return {aid: min(1.0, 0.5 + 0.2 * (s.velocity / 30.0))\n",
        "                for aid, s in states.items()}\n",
        "\n",
        "    def resolve_conflicts(self, conflicts: List[Tuple[str, str, str]],\n",
        "                          states: Dict[str, AgentState],\n",
        "                          goals: Dict[str, str],\n",
        "                          priorities: Dict[str, float]) -> Dict[str, CoordinationMessage]:\n",
        "        msgs = {\n",
        "            aid: CoordinationMessage(aid, goals.get(aid, \"Navigate safely\"),\n",
        "                                     priorities.get(aid, 0.5), [], time.time())\n",
        "            for aid in states.keys()\n",
        "        }\n",
        "\n",
        "        for a1, a2, ctype in conflicts:\n",
        "            self.resolution_count += 1\n",
        "            winner = a1 if priorities[a1] > priorities[a2] else a2\n",
        "            loser = a2 if winner == a1 else a1\n",
        "            msgs[loser].coordination_constraints.append(f\"Yield to {winner}\")\n",
        "            msgs[loser].assigned_goal = \"Maintain safe distance\"\n",
        "\n",
        "        return msgs\n",
        "\n",
        "    def coordinate(self, proposals: Dict[str, AgentReport],\n",
        "                   states: Dict[str, AgentState]) -> Dict[str, CoordinationMessage]:\n",
        "        if not self.config.enable_master_agent:\n",
        "            return {\n",
        "                aid: CoordinationMessage(aid, proposals[aid].proposed_goal if aid in proposals else \"Navigate\",\n",
        "                                        0.5, [], time.time())\n",
        "                for aid in states.keys()\n",
        "            }\n",
        "\n",
        "        goals = {aid: r.proposed_goal for aid, r in proposals.items()}\n",
        "        conflicts = self.detect_conflicts(goals, states)\n",
        "        priorities = self.compute_priorities(states, goals)\n",
        "        return self.resolve_conflicts(conflicts, states, goals, priorities)\n",
        "\n",
        "    def get_stats(self) -> Dict:\n",
        "        return {'conflicts': self.conflict_count, 'resolutions': self.resolution_count}\n",
        "\n",
        "master_agent = MasterCoordinationModule(llm, framework_config)\n",
        "print(f\"✓ Master Agent ready (enabled: {framework_config.enable_master_agent})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IhWG7Xs4f-V"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PHASE 9: HIERARCHICAL PLANNING MODULE \n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PHASE 9: Hierarchical Planning Module\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "class HierarchicalPlanningModule:\n",
        "    \"\"\"Goal-Plan-Action pipeline with coordination\"\"\"\n",
        "\n",
        "    def __init__(self, llm: LLMInterface, memory: RAGMemoryModule,\n",
        "                 config: FrameworkConfig):\n",
        "        self.llm = llm\n",
        "        self.memory = memory\n",
        "        self.config = config\n",
        "        self.history: List[Dict] = []\n",
        "\n",
        "    def clarify_goal(self, context: str, assigned_goal: str,\n",
        "                     memories: List[Experience]) -> str:\n",
        "        mem_text = \"\"\n",
        "        if memories:\n",
        "            mem_text = f\"\\nPast goals that worked: {', '.join(m.goal[:30] for m in memories[:2])}\"\n",
        "\n",
        "        prompt = f\"\"\"Context: {context[:200]}\n",
        "Assigned: {assigned_goal}{mem_text}\n",
        "\n",
        "Clarify goal. Reply JSON only:\n",
        "{{\"goal\": \"specific goal\", \"reasoning\": \"why\"}}\"\"\"\n",
        "\n",
        "        response = self.llm.generate(prompt, \"Reply JSON only.\", json_mode=True)\n",
        "        try:\n",
        "            return json.loads(response).get(\"goal\", assigned_goal)\n",
        "        except:\n",
        "            return assigned_goal\n",
        "\n",
        "    def generate_plan(self, context: str, goal: str,\n",
        "                      memories: List[Experience],\n",
        "                      constraints: List[str]) -> List[str]:\n",
        "        c_text = \", \".join(constraints) if constraints else \"None\"\n",
        "\n",
        "        prompt = f\"\"\"Goal: {goal}\n",
        "Constraints: {c_text}\n",
        "\n",
        "Create plan. Reply JSON only:\n",
        "{{\"plan\": [\"step1\", \"step2\"], \"outcome\": \"expected result\"}}\"\"\"\n",
        "\n",
        "        response = self.llm.generate(prompt, \"Reply JSON only.\", json_mode=True)\n",
        "        try:\n",
        "            return json.loads(response).get(\"plan\", [\"Maintain course\"])\n",
        "        except:\n",
        "            return [\"Maintain course\"]\n",
        "\n",
        "    def select_action(self, context: str, goal: str, plan: List[str],\n",
        "                      constraints: List[str]) -> Tuple[Action, float]:\n",
        "        prompt = f\"\"\"Goal: {goal}\n",
        "Plan: {'; '.join(plan[:2])}\n",
        "Actions: IDLE, ACCELERATE, DECELERATE, LANE_CHANGE_LEFT, LANE_CHANGE_RIGHT\n",
        "\n",
        "Pick best action. Reply JSON only:\n",
        "{{\"action\": \"ACTION_NAME\", \"confidence\": 0.8}}\"\"\"\n",
        "\n",
        "        response = self.llm.generate(prompt, \"Reply JSON only. action must be one of the listed options.\", json_mode=True)\n",
        "        try:\n",
        "            result = json.loads(response)\n",
        "            action_name = result.get(\"action\", \"IDLE\").upper().strip()\n",
        "            conf = float(result.get(\"confidence\", 0.5))\n",
        "\n",
        "            action_map = {\n",
        "                \"IDLE\": Action.IDLE, \"ACCELERATE\": Action.ACCELERATE,\n",
        "                \"DECELERATE\": Action.DECELERATE, \"LANE_CHANGE_LEFT\": Action.LANE_CHANGE_LEFT,\n",
        "                \"LANE_CHANGE_RIGHT\": Action.LANE_CHANGE_RIGHT\n",
        "            }\n",
        "            return action_map.get(action_name, Action.IDLE), conf\n",
        "        except:\n",
        "            return Action.IDLE, 0.5\n",
        "\n",
        "    def plan_and_act(self, agent_id: str, context: str,\n",
        "                     coord_msg: CoordinationMessage,\n",
        "                     current_time: float) -> Tuple[str, List[str], Action, float]:\n",
        "        memories = self.memory.retrieve(context, current_time)\n",
        "        goal = self.clarify_goal(context, coord_msg.assigned_goal, memories)\n",
        "        plan = self.generate_plan(context, goal, memories, coord_msg.coordination_constraints)\n",
        "        action, conf = self.select_action(context, goal, plan, coord_msg.coordination_constraints)\n",
        "\n",
        "        self.history.append({'agent': agent_id, 'time': current_time,\n",
        "                            'goal': goal, 'action': action.name})\n",
        "        return goal, plan, action, conf\n",
        "\n",
        "planning_module = HierarchicalPlanningModule(llm, memory_module, framework_config)\n",
        "print(\"✓ Planning Module ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f37QjRXl4jSN"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PHASE 10: REFLECTION MODULE\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PHASE 10: Reflection Module\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "class ReflectionModule:\n",
        "    \"\"\"Evaluate episodes and update memory\"\"\"\n",
        "\n",
        "    def __init__(self, llm: LLMInterface, memory: RAGMemoryModule,\n",
        "                 embedding_module: EmbeddingModule, config: FrameworkConfig):\n",
        "        self.llm = llm\n",
        "        self.memory = memory\n",
        "        self.embedding = embedding_module\n",
        "        self.config = config\n",
        "        self.reflect_count = 0\n",
        "        self.improve_count = 0\n",
        "\n",
        "    def should_reflect(self, rewards: List[float], collision: bool) -> bool:\n",
        "        if not self.config.enable_reflection:\n",
        "            return False\n",
        "        if collision:\n",
        "            return True\n",
        "        if rewards and np.mean(rewards) < self.config.theta_reflect:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def reflect_on_experience(self, exp: Experience,\n",
        "                              successful: List[Experience]) -> Optional[Experience]:\n",
        "        self.reflect_count += 1\n",
        "\n",
        "        succ_text = \"\"\n",
        "        if successful:\n",
        "            succ_text = f\"\\nSuccessful examples: {', '.join(s.action.name for s in successful[:2])}\"\n",
        "\n",
        "        prompt = f\"\"\"Experience to improve:\n",
        "{exp.description[:100]}\n",
        "Action: {exp.action.name}, Reward: {exp.reward:.1f}\n",
        "{succ_text}\n",
        "\n",
        "Suggest improvement. Reply JSON only:\n",
        "{{\"corrected_action\": \"ACTION_NAME\", \"reason\": \"why better\"}}\"\"\"\n",
        "\n",
        "        response = self.llm.generate(prompt, \"Reply JSON only.\", json_mode=True)\n",
        "        try:\n",
        "            result = json.loads(response)\n",
        "            action_map = {\"IDLE\": Action.IDLE, \"ACCELERATE\": Action.ACCELERATE,\n",
        "                         \"DECELERATE\": Action.DECELERATE, \"LANE_CHANGE_LEFT\": Action.LANE_CHANGE_LEFT,\n",
        "                         \"LANE_CHANGE_RIGHT\": Action.LANE_CHANGE_RIGHT}\n",
        "\n",
        "            new_action = action_map.get(result.get(\"corrected_action\", \"IDLE\").upper(), Action.IDLE)\n",
        "\n",
        "            improved = Experience(\n",
        "                experience_id=f\"{exp.experience_id}_improved\",\n",
        "                description=exp.description, goal=exp.goal, plan=exp.plan,\n",
        "                action=new_action, reward=exp.reward + 0.5,\n",
        "                timestamp=exp.timestamp, scenario_type=exp.scenario_type, verified=True\n",
        "            )\n",
        "            improved.embedding = self.embedding.embed(f\"{improved.description} {improved.goal}\")\n",
        "            self.improve_count += 1\n",
        "            return improved\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def process_episode(self, experiences: List[Experience],\n",
        "                        rewards: List[float], collision: bool):\n",
        "        if not self.should_reflect(rewards, collision):\n",
        "            for exp in experiences:\n",
        "                if exp.reward > self.config.theta_high:\n",
        "                    exp.verified = True\n",
        "                    self.memory.add_experience(exp)\n",
        "            return\n",
        "\n",
        "        successful = [e for e in self.memory.vector_store.get_all_experiences()\n",
        "                     if e.reward > self.config.theta_high][:3]\n",
        "\n",
        "        for exp in experiences:\n",
        "            if exp.reward < self.config.theta_reflect:\n",
        "                improved = self.reflect_on_experience(exp, successful)\n",
        "                if improved:\n",
        "                    self.memory.add_experience(improved)\n",
        "            elif exp.reward > self.config.theta_high:\n",
        "                exp.verified = True\n",
        "                self.memory.add_experience(exp)\n",
        "\n",
        "    def get_stats(self) -> Dict:\n",
        "        return {'reflections': self.reflect_count, 'improvements': self.improve_count}\n",
        "\n",
        "reflection_module = ReflectionModule(llm, memory_module, embedding_module, framework_config)\n",
        "print(f\"✓ Reflection Module ready (enabled: {framework_config.enable_reflection})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLNND7rf4nOL"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PHASE 11: METRICS AND EVALUATION\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PHASE 11: Metrics and Evaluation\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "@dataclass\n",
        "class EpisodeMetrics:\n",
        "    episode_id: int\n",
        "    total_reward: float\n",
        "    avg_reward: float\n",
        "    collision: bool\n",
        "    conflicts: int\n",
        "    verified_retrievals: int\n",
        "    completion: float\n",
        "\n",
        "class MetricsCollector:\n",
        "    def __init__(self):\n",
        "        self.episodes: List[EpisodeMetrics] = []\n",
        "        self.stats = defaultdict(list)\n",
        "\n",
        "    def add_episode(self, ep_id: int, rewards: List[float], collision: bool,\n",
        "                    master_stats: Dict, memory_stats: Dict, completion: float):\n",
        "        m = EpisodeMetrics(\n",
        "            episode_id=ep_id,\n",
        "            total_reward=sum(rewards) if rewards else 0,\n",
        "            avg_reward=np.mean(rewards) if rewards else 0,\n",
        "            collision=collision,\n",
        "            conflicts=master_stats.get('conflicts', 0),\n",
        "            verified_retrievals=memory_stats.get('verified', 0),\n",
        "            completion=completion\n",
        "        )\n",
        "        self.episodes.append(m)\n",
        "\n",
        "        self.stats['reward'].append(m.total_reward)\n",
        "        self.stats['collision'].append(1 if collision else 0)\n",
        "\n",
        "        total_ret = memory_stats.get('candidates', 1)\n",
        "        verified = memory_stats.get('verified', 0)\n",
        "        self.stats['fc'].append(verified / max(total_ret, 1))\n",
        "\n",
        "    def get_summary(self) -> Dict:\n",
        "        if not self.episodes:\n",
        "            return {}\n",
        "        return {\n",
        "            'episodes': len(self.episodes),\n",
        "            'avg_reward': np.mean(self.stats['reward']),\n",
        "            'collision_rate': np.mean(self.stats['collision']),\n",
        "            'factual_consistency': np.mean(self.stats['fc']),\n",
        "            'total_collisions': sum(1 for e in self.episodes if e.collision)\n",
        "        }\n",
        "\n",
        "    def plot(self):\n",
        "        if not self.episodes:\n",
        "            return\n",
        "\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
        "\n",
        "        axes[0].plot(self.stats['reward'])\n",
        "        axes[0].set_title('Rewards')\n",
        "        axes[0].set_xlabel('Episode')\n",
        "\n",
        "        cum_col = np.cumsum(self.stats['collision']) / (np.arange(len(self.stats['collision'])) + 1)\n",
        "        axes[1].plot(cum_col)\n",
        "        axes[1].set_title('Collision Rate')\n",
        "        axes[1].set_xlabel('Episode')\n",
        "\n",
        "        axes[2].plot(self.stats['fc'])\n",
        "        axes[2].set_title('Factual Consistency')\n",
        "        axes[2].set_xlabel('Episode')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('metrics.png', dpi=100)\n",
        "        plt.show()\n",
        "\n",
        "metrics = MetricsCollector()\n",
        "print(\"✓ Metrics Collector ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hoL5eWX4q-H"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =============================================================================\n",
        "# PHASE 12: MAIN FRAMEWORK \n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PHASE 12: Main KoMA-RAG Framework \")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "class KoMARAGFramework:\n",
        "    \"\"\"Complete KoMA-RAG Framework\"\"\"\n",
        "\n",
        "    def __init__(self, fw_config: FrameworkConfig, exp_config: ExperimentConfig,\n",
        "                 api_config: APIConfig):\n",
        "        self.fw_config = fw_config\n",
        "        self.exp_config = exp_config\n",
        "\n",
        "        # Initialize modules\n",
        "        self.llm = LLMInterface(api_config)\n",
        "        self.embedding = EmbeddingModule()\n",
        "        self.vector_store = FAISSVectorStore(self.embedding.embedding_dim)\n",
        "        self.verification = VerificationModule(self.llm, self.embedding, fw_config)\n",
        "        self.memory = RAGMemoryModule(self.vector_store, self.embedding, self.verification, fw_config)\n",
        "        self.env = HighwayEnvironment(fw_config)\n",
        "        self.intent = IntentInferenceModule(self.llm, fw_config)\n",
        "        self.master = MasterCoordinationModule(self.llm, fw_config)\n",
        "        self.planning = HierarchicalPlanningModule(self.llm, self.memory, fw_config)\n",
        "        self.reflection = ReflectionModule(self.llm, self.memory, self.embedding, fw_config)\n",
        "        self.metrics = MetricsCollector()\n",
        "\n",
        "        self._seed_memories()\n",
        "\n",
        "    def _seed_memories(self):\n",
        "        seeds = [\n",
        "            (\"Highway clear ahead\", \"Maintain speed\", \"Stay course\", Action.IDLE, 0.8),\n",
        "            (\"Slow vehicle ahead\", \"Overtake safely\", \"Change lane\", Action.LANE_CHANGE_LEFT, 0.7),\n",
        "            (\"Traffic slowing\", \"Match speed\", \"Decelerate\", Action.DECELERATE, 0.75),\n",
        "        ]\n",
        "        for i, (desc, goal, plan, action, reward) in enumerate(seeds):\n",
        "            exp = Experience(f\"seed_{i}\", desc, goal, plan, action, reward,\n",
        "                           timestamp=0, scenario_type=\"highway\", verified=True)\n",
        "            exp.embedding = self.embedding.embed(f\"{desc} {goal}\")\n",
        "            self.vector_store.add_experience(exp)\n",
        "        print(f\"✓ Seeded {len(seeds)} experiences\")\n",
        "\n",
        "    def run_episode(self, ep_id: int) -> Dict:\n",
        "        scenario = self.env.reset()\n",
        "        experiences = []\n",
        "\n",
        "        print(f\"\\n--- Episode {ep_id} ---\")\n",
        "\n",
        "        # Print full scenario description (no truncation)\n",
        "        if self.exp_config.verbose:\n",
        "            print(scenario.to_text())  # \n",
        "\n",
        "        while not self.env.is_done():\n",
        "            t = self.env.current_time\n",
        "\n",
        "            # Agent proposals\n",
        "            proposals = {}\n",
        "            for aid, state in self.env.ego_agents.items():\n",
        "                ctx = self.env.get_agent_context(aid)\n",
        "                nearby = [v.state for v in self.env.idm_vehicles.values()]\n",
        "                intents = self.intent.infer_intentions(state, nearby, t)\n",
        "                proposals[aid] = AgentReport(aid, state, \"Navigate safely\", intents, 0.8, t)\n",
        "\n",
        "            # Master coordination\n",
        "            coord_msgs = self.master.coordinate(proposals, self.env.ego_agents)\n",
        "\n",
        "            # Agent actions\n",
        "            for aid, state in self.env.ego_agents.items():\n",
        "                ctx = self.env.get_agent_context(aid)\n",
        "                goal, plan, action, conf = self.planning.plan_and_act(aid, ctx, coord_msgs[aid], t)\n",
        "\n",
        "                reward, collision = self.env.execute_action(aid, action)\n",
        "\n",
        "                exp = Experience(f\"ep{ep_id}_t{t:.1f}_{aid}\", ctx[:150], goal, str(plan),\n",
        "                               action, reward, timestamp=t, scenario_type=\"highway\")\n",
        "                exp.embedding = self.embedding.embed(f\"{ctx[:100]} {goal}\")\n",
        "                experiences.append(exp)\n",
        "\n",
        "                if self.exp_config.verbose and self.env.timestep % 10 == 0:\n",
        "                    print(f\"  t={t:.1f} {aid}: {action.name} r={reward:.2f}\")\n",
        "\n",
        "            self.env.step()\n",
        "\n",
        "        # Reflection\n",
        "        self.reflection.process_episode(experiences, self.env.episode_rewards, self.env.collision_occurred)\n",
        "\n",
        "        # Metrics\n",
        "        completion = self.env.timestep / self.fw_config.max_timesteps\n",
        "        self.metrics.add_episode(ep_id, self.env.episode_rewards, self.env.collision_occurred,\n",
        "                                self.master.get_stats(), self.memory.get_stats(), completion)\n",
        "\n",
        "        result = {'episode': ep_id, 'reward': sum(self.env.episode_rewards),\n",
        "                 'collision': self.env.collision_occurred, 'steps': self.env.timestep}\n",
        "        print(f\"Episode {ep_id}: Reward={result['reward']:.1f}, Collision={result['collision']}\")\n",
        "        return result\n",
        "\n",
        "    def run_experiment(self):\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"STARTING KOMA-RAG EXPERIMENT\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        results = []\n",
        "        for ep in range(self.exp_config.num_episodes):\n",
        "            results.append(self.run_episode(ep))\n",
        "\n",
        "        summary = self.metrics.get_summary()\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"EXPERIMENT COMPLETE\")\n",
        "        print(\"=\" * 60)\n",
        "        for k, v in summary.items():\n",
        "            print(f\"  {k}: {v:.4f}\" if isinstance(v, float) else f\"  {k}: {v}\")\n",
        "\n",
        "        return results, summary\n",
        "\n",
        "print(\"✓ KoMA-RAG Framework defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfKZLlGP4wKT"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PHASE 13: ABLATION STUDY CONFIGURATION\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PHASE 13: Ablation Study Configuration\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def run_ablation_study(api_config: APIConfig, num_episodes: int = 5):\n",
        "    \"\"\"\n",
        "    Run ablation studies comparing different configurations\n",
        "\n",
        "    Baselines:\n",
        "    1. Base KoMA: No verification, no Master Agent\n",
        "    2. KoMA + Verification: RAG without Master\n",
        "    3. KoMA + Master: Master without RAG verification\n",
        "    4. KoMA-RAG (Full): Both RAG and Master\n",
        "    \"\"\"\n",
        "\n",
        "    configurations = {\n",
        "        \"Base_KoMA\": {\n",
        "            \"enable_master_agent\": False,\n",
        "            \"enable_rag_verification\": False,\n",
        "            \"enable_reflection\": True,\n",
        "            \"enable_intent_inference\": True\n",
        "        },\n",
        "        \"KoMA_Verification\": {\n",
        "            \"enable_master_agent\": False,\n",
        "            \"enable_rag_verification\": True,\n",
        "            \"enable_reflection\": True,\n",
        "            \"enable_intent_inference\": True\n",
        "        },\n",
        "        \"KoMA_Master\": {\n",
        "            \"enable_master_agent\": True,\n",
        "            \"enable_rag_verification\": False,\n",
        "            \"enable_reflection\": True,\n",
        "            \"enable_intent_inference\": True\n",
        "        },\n",
        "        \"KoMA_RAG_Full\": {\n",
        "            \"enable_master_agent\": True,\n",
        "            \"enable_rag_verification\": True,\n",
        "            \"enable_reflection\": True,\n",
        "            \"enable_intent_inference\": True\n",
        "        }\n",
        "    }\n",
        "\n",
        "    ablation_results = {}\n",
        "\n",
        "    for config_name, config_params in configurations.items():\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Running Ablation: {config_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Create framework config\n",
        "        framework_cfg = FrameworkConfig(**config_params)\n",
        "        experiment_cfg = ExperimentConfig(\n",
        "            experiment_name=config_name,\n",
        "            num_episodes=num_episodes,\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        # Run experiment\n",
        "        framework = KoMARAGFramework(framework_cfg, experiment_cfg, api_config)\n",
        "        results, summary = framework.run_experiment()\n",
        "\n",
        "        ablation_results[config_name] = summary\n",
        "\n",
        "    # Compare results\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ABLATION STUDY RESULTS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Create comparison table\n",
        "    comparison_df = pd.DataFrame(ablation_results).T\n",
        "    print(comparison_df.to_string())\n",
        "\n",
        "    # Plot comparison\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "    configs = list(ablation_results.keys())\n",
        "\n",
        "    # Average Reward\n",
        "    rewards = [ablation_results[c].get('avg_reward', 0) for c in configs]\n",
        "    axes[0].bar(configs, rewards, color=['gray', 'blue', 'green', 'red'])\n",
        "    axes[0].set_title('Average Reward')\n",
        "    axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Collision Rate\n",
        "    collisions = [ablation_results[c].get('collision_rate', 0) for c in configs]\n",
        "    axes[1].bar(configs, collisions, color=['gray', 'blue', 'green', 'red'])\n",
        "    axes[1].set_title('Collision Rate (lower is better)')\n",
        "    axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Factual Consistency\n",
        "    fc = [ablation_results[c].get('factual_consistency', 0) for c in configs]\n",
        "    axes[2].bar(configs, fc, color=['gray', 'blue', 'green', 'red'])\n",
        "    axes[2].set_title('Factual Consistency')\n",
        "    axes[2].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('ablation_study_results.png', dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "    return ablation_results, comparison_df\n",
        "\n",
        "print(\"✓ Ablation study functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp25AsYG4y5R"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PHASE 14: RUN EXPERIMENT\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PHASE 13: Running Experiment\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Set seeds\n",
        "np.random.seed(experiment_config.seed)\n",
        "random.seed(experiment_config.seed)\n",
        "\n",
        "# Create framework\n",
        "koma_rag = KoMARAGFramework(framework_config, experiment_config, api_config)\n",
        "\n",
        "# Run\n",
        "results, summary = koma_rag.run_experiment()\n",
        "\n",
        "# Plot\n",
        "koma_rag.metrics.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eARp9hfK434Y"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PHASE 15: RUN ABLATION STUDY (Optional)\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PHASE 15: Ablation Study (Optional)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "RUN_ABLATION = True  # Set to True to run ablation study\n",
        "\n",
        "if RUN_ABLATION:\n",
        "    ablation_results, comparison_df = run_ablation_study(\n",
        "        api_config=api_config,\n",
        "        num_episodes=1  # Fewer episodes for faster ablation\n",
        "    )\n",
        "\n",
        "    # Save results\n",
        "    comparison_df.to_csv('ablation_results.csv')\n",
        "    print(\"\\n✓ Ablation results saved to 'ablation_results.csv'\")\n",
        "\n",
        "# =============================================================================\n",
        "# PHASE 16: EXPORT AND SAVE RESULTS\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PHASE 16: Exporting Results\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Save detailed results\n",
        "final_results = {\n",
        "    'experiment_config': asdict(experiment_config),\n",
        "    'framework_config': {\n",
        "        k: v for k, v in asdict(framework_config).items()\n",
        "        if not callable(v)\n",
        "    },\n",
        "    'summary': summary,\n",
        "    'episode_results': results,\n",
        "    'llm_stats': koma_rag.llm.get_stats(),\n",
        "    'memory_stats': koma_rag.memory.get_stats(),\n",
        "    'master_stats': koma_rag.master_agent.get_stats(),\n",
        "    'reflection_stats': koma_rag.reflection.get_stats()\n",
        "}\n",
        "\n",
        "# Convert to JSON-serializable format\n",
        "def make_serializable(obj):\n",
        "    if isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    elif isinstance(obj, dict):\n",
        "        return {k: make_serializable(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, list):\n",
        "        return [make_serializable(i) for i in obj]\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "serializable_results = make_serializable(final_results)\n",
        "\n",
        "with open('koma_rag_results.json', 'w') as f:\n",
        "    json.dump(serializable_results, f, indent=2, default=str)\n",
        "\n",
        "print(\"✓ Results saved to 'koma_rag_results.json'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oTqoI5l2IPI"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# FINAL SUMMARY\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"KOMA-RAG FRAMEWORK EXECUTION COMPLETE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\"\"\n",
        "Generated Files:\n",
        "  1. koma_rag_metrics.png - Performance visualization\n",
        "  2. koma_rag_results.json - Detailed results\n",
        "  3. ablation_results.csv - Ablation study comparison (if enabled)\n",
        "  4. ablation_study_results.png - Ablation visualization (if enabled)\n",
        "\n",
        "Key Metrics:\n",
        "\"\"\")\n",
        "\n",
        "for key, value in summary.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"  • {key}: {value:.4f}\")\n",
        "    else:\n",
        "        print(f\"  • {key}: {value}\")\n",
        "\n",
        "print(\"\"\"\n",
        "Framework Modules Demonstrated:\n",
        "  ✓ Phase 1-2: Configuration and Data Structures\n",
        "  ✓ Phase 3: LLM Interface (Groq/OpenAI/Mock)\n",
        "  ✓ Phase 4: FAISS Vector Store and Embeddings\n",
        "  ✓ Phase 5: RAG-Enhanced Memory with Verification\n",
        "  ✓ Phase 6: Highway Environment Simulation\n",
        "  ✓ Phase 7: Intent Inference Module\n",
        "  ✓ Phase 8: Master Coordination Module\n",
        "  ✓ Phase 9: Hierarchical Planning (Goal-Plan-Action)\n",
        "  ✓ Phase 10: Reflection Module\n",
        "  ✓ Phase 11-12: Metrics and Main Pipeline\n",
        "  ✓ Phase 13-15: Ablation Studies\n",
        "  ✓ Phase 16: Results Export\n",
        "\n",
        "To modify for your paper:\n",
        "  1. Adjust FrameworkConfig parameters for different scenarios\n",
        "  2. Toggle ablation flags to compare baselines\n",
        "  3. Increase num_episodes for more robust statistics\n",
        "  4. Add your API key for real LLM responses\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16uSkcj52y2R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
